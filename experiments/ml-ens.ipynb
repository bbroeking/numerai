{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "integral-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from helpers.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "logical-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data\n"
     ]
    }
   ],
   "source": [
    "DIR = \"/Users/brianbroeking/projects/numerai/data\"\n",
    "train_static, val_static, tournament_static = load_data(DIR, reduce_memory=True)\n",
    "features_list = generate_features_list(train_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "western-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def era_boost_train(X, y, era_col, proportion=0.5,\n",
    "                    trees_per_step=10, num_iters=200,\n",
    "                    one_shot=False, tree_method='hist',\n",
    "                    test_model=None, note=None):\n",
    "    print(f\"\\n#### Era boost train with proportion {proportion:0.3f} ####\\n\")\n",
    "    if note is not None:\n",
    "        print(note)\n",
    "    if one_shot:\n",
    "        trees_per_step = trees_per_step * num_iters\n",
    "        num_iters=1\n",
    "\n",
    "    if test_model is None:\n",
    "        print(f\"Train {num_iters} iterations\")\n",
    "        print(f\"Train {trees_per_step} rounds per iteration\")\n",
    "    else:\n",
    "        print(\"Testing model performance\")\n",
    "    features = X.columns\n",
    "    new_df = X.copy()\n",
    "    new_df[\"target\"] = y\n",
    "    new_df[\"era\"] = era_col\n",
    "    for i in range(num_iters):\n",
    "        print(f\"\\nIteration {i+1}:\\n\")\n",
    "        if test_model is None:\n",
    "            if i==0:\n",
    "                model = xgboost.XGBRegressor(max_depth=5,\n",
    "                                             learning_rate=0.001,\n",
    "                                             n_estimators=trees_per_step,\n",
    "                                             n_jobs=-1,\n",
    "                                             colsample_bytree=0.1,\n",
    "                                             gamma=0.2,\n",
    "                                             tree_method=tree_method)\n",
    "                model.fit(X, y)\n",
    "            else:\n",
    "                model.n_estimators += trees_per_step\n",
    "                booster = model.get_booster()\n",
    "                print(\"fitting on worst eras\")\n",
    "                model.fit(worst_df[features], worst_df[\"target\"], xgb_model=booster)\n",
    "        else:\n",
    "            if i == 0:\n",
    "                model = test_model\n",
    "            else:\n",
    "                model.n_estimators += trees_per_step\n",
    "                booster = model.get_booster()\n",
    "                print(\"fitting on worst eras\")\n",
    "                model.fit(worst_df[features], worst_df[\"target\"], xgb_model=booster)\n",
    "        # score each era\n",
    "        print(\"predicting on train\")\n",
    "        preds = model.predict(X)\n",
    "        new_df[\"pred\"] = preds\n",
    "        era_scores = pd.Series(index=new_df[\"era\"].unique())\n",
    "        print(\"getting per era scores\")\n",
    "        for era in new_df[\"era\"].unique():\n",
    "            era_df = new_df[new_df[\"era\"] == era]\n",
    "            print(spearmanr(era_df[\"pred\"], era_df[\"target\"])[0])\n",
    "            era_scores[era] = spearmanr(era_df[\"pred\"], era_df[\"target\"])[0]\n",
    "        era_scores.sort_values(inplace=True)\n",
    "        worst_eras = era_scores[era_scores <= era_scores.quantile(proportion)].index\n",
    "        print(list(worst_eras))\n",
    "        worst_df = new_df[new_df[\"era\"].isin(worst_eras)]\n",
    "        era_scores.sort_index(inplace=True)\n",
    "        era_scores.plot(kind=\"bar\")\n",
    "        print(\"performance over time\")\n",
    "        plt.show()\n",
    "        print(\"autocorrelation\")\n",
    "        print(ar1(era_scores))\n",
    "#         if (ar1(era_scores)) < 0.1:\n",
    "#             return model\n",
    "        print(\"mean correlation\")\n",
    "        print(np.mean(era_scores))\n",
    "        print(\"sharpe\")\n",
    "        print(np.mean(era_scores)/np.std(era_scores))\n",
    "        print(\"smart sharpe\")\n",
    "        print(smart_sharpe(era_scores))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "uniform-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_model(train_with_group, tournament_with_group):\n",
    "    ft_corr_list = random.sample(features_list, 63)\n",
    "    train, tournament = generate_polynomial_features(ft_corr_list, train_with_group, tournament_with_group)\n",
    "    X_train, y_train = clean_for_xgboost(train)\n",
    "    X_tournament, y_tournament = clean_for_xgboost(tournament)\n",
    "\n",
    "    model = era_boost_train(X_train, y_train,\n",
    "                            era_col=train[\"era\"], proportion=0.5,\n",
    "                            trees_per_step=3, num_iters=8)\n",
    "    \n",
    "    return ft_corr_list, X_tournament, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "several-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-95c56e3387b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mft_corr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tournament\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_with_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournament_with_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mft_corrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_corr_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mxtournaments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tournament\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fa02736d364d>\u001b[0m in \u001b[0;36mgenerate_model\u001b[0;34m(train_with_group, tournament_with_group)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_with_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournament_with_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mft_corr_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m63\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournament\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_polynomial_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_corr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_with_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtournament_with_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_for_xgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mX_tournament\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tournament\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_for_xgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtournament\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/numerai/helpers/utils.py\u001b[0m in \u001b[0;36mgenerate_polynomial_features\u001b[0;34m(feature_list, train, tournament)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0minteractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mX_train_interact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mX_best_tournament_inter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtournament\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_interact\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1829\u001b[0m                         \u001b[0;31m# XP[:, start:end] are terms of degree d - 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m                         \u001b[0;31m# that exclude feature #feature_idx.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1831\u001b[0;31m                         np.multiply(XP[:, start:end],\n\u001b[0m\u001b[1;32m   1832\u001b[0m                                     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfeature_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m                                     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnext_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_with_group = get_group_stats(train_static)\n",
    "tournament_with_group = get_group_stats(tournament_static)\n",
    "\n",
    "# generate many models\n",
    "ft_corrs = []\n",
    "xtournaments = []\n",
    "models = []\n",
    "for i in range(0, 5):\n",
    "    ft_corr_list, X_tournament, model = generate_model(train_with_group, tournament_with_group)\n",
    "    ft_corrs.append(ft_corr_list)\n",
    "    xtournaments.append(X_tournament)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acknowledged-cooler",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import set of models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "seed = 101\n",
    "ensemble = SuperLearner(scorer=correlation_score, random_state=seed, verbose=2)\n",
    "ensemble.add([load_model(f'model_{str(i)}.pickle.dat') for i in range(0,5)])\n",
    "ensemble.add_meta(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ensemble\n",
    "ensemble.fit(X[:75], y[:75])\n",
    "\n",
    "# Predict\n",
    "preds = ensemble.predict(X[75:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
