{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "decent-johnson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix, mean_absolute_error\n",
    "\n",
    "import xgboost\n",
    "import numerapi\n",
    "NAPI = numerapi.NumerAPI(verbosity=\"info\")\n",
    "import random as rn\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from bayes_opt import BayesianOptimization\n",
    "import os\n",
    "import uuid\n",
    "import pickle\n",
    "\n",
    "from utils import *\n",
    "from poly_features import *\n",
    "from xgboost_feval import *\n",
    "DIR = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "therapeutic-asset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence3</th>\n",
       "      <th>feature_intelligence4</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence6</th>\n",
       "      <th>feature_intelligence7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_charisma_skew</th>\n",
       "      <th>feature_dexterity_mean</th>\n",
       "      <th>feature_dexterity_std</th>\n",
       "      <th>feature_dexterity_skew</th>\n",
       "      <th>feature_strength_mean</th>\n",
       "      <th>feature_strength_std</th>\n",
       "      <th>feature_strength_skew</th>\n",
       "      <th>feature_constitution_mean</th>\n",
       "      <th>feature_constitution_std</th>\n",
       "      <th>feature_constitution_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000315175b67977</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004783</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.200446</td>\n",
       "      <td>-0.607620</td>\n",
       "      <td>0.480263</td>\n",
       "      <td>0.292829</td>\n",
       "      <td>-0.372064</td>\n",
       "      <td>0.427632</td>\n",
       "      <td>0.275720</td>\n",
       "      <td>0.276155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n0014af834a96cdd</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021737</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.249312</td>\n",
       "      <td>0.382267</td>\n",
       "      <td>0.407895</td>\n",
       "      <td>0.309866</td>\n",
       "      <td>0.220625</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.334080</td>\n",
       "      <td>-0.794938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n001c93979ac41d4</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600709</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.355973</td>\n",
       "      <td>0.624266</td>\n",
       "      <td>0.203947</td>\n",
       "      <td>0.289777</td>\n",
       "      <td>1.258705</td>\n",
       "      <td>0.418860</td>\n",
       "      <td>0.331755</td>\n",
       "      <td>0.179824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n0034e4143f22a13</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.238108</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.118658</td>\n",
       "      <td>-0.308327</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.332027</td>\n",
       "      <td>0.332149</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.321619</td>\n",
       "      <td>0.541559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n00679d1a636062f</td>\n",
       "      <td>era1</td>\n",
       "      <td>train</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329475</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.138675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.262660</td>\n",
       "      <td>1.548723</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.394836</td>\n",
       "      <td>0.092206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   era data_type  feature_intelligence1  \\\n",
       "0  n000315175b67977  era1     train                   0.00   \n",
       "1  n0014af834a96cdd  era1     train                   0.00   \n",
       "2  n001c93979ac41d4  era1     train                   0.25   \n",
       "3  n0034e4143f22a13  era1     train                   1.00   \n",
       "4  n00679d1a636062f  era1     train                   0.25   \n",
       "\n",
       "   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n",
       "0                   0.50                   0.25                   0.00   \n",
       "1                   0.00                   0.00                   0.25   \n",
       "2                   0.50                   0.25                   0.25   \n",
       "3                   0.00                   0.00                   0.50   \n",
       "4                   0.25                   0.25                   0.25   \n",
       "\n",
       "   feature_intelligence5  feature_intelligence6  feature_intelligence7  ...  \\\n",
       "0                    0.5                   0.25                   0.25  ...   \n",
       "1                    0.5                   0.00                   0.00  ...   \n",
       "2                    1.0                   0.75                   0.75  ...   \n",
       "3                    0.5                   0.25                   0.25  ...   \n",
       "4                    0.0                   0.25                   0.50  ...   \n",
       "\n",
       "   feature_charisma_skew  feature_dexterity_mean  feature_dexterity_std  \\\n",
       "0              -0.004783                0.696429               0.200446   \n",
       "1              -0.021737                0.267857               0.249312   \n",
       "2              -0.600709                0.446429               0.355973   \n",
       "3              -0.238108                0.232143               0.118658   \n",
       "4              -0.329475                0.500000               0.138675   \n",
       "\n",
       "   feature_dexterity_skew  feature_strength_mean  feature_strength_std  \\\n",
       "0               -0.607620               0.480263              0.292829   \n",
       "1                0.382267               0.407895              0.309866   \n",
       "2                0.624266               0.203947              0.289777   \n",
       "3               -0.308327               0.394737              0.332027   \n",
       "4                0.000000               0.342105              0.262660   \n",
       "\n",
       "   feature_strength_skew  feature_constitution_mean  feature_constitution_std  \\\n",
       "0              -0.372064                   0.427632                  0.275720   \n",
       "1               0.220625                   0.644737                  0.334080   \n",
       "2               1.258705                   0.418860                  0.331755   \n",
       "3               0.332149                   0.429825                  0.321619   \n",
       "4               1.548723                   0.508772                  0.394836   \n",
       "\n",
       "   feature_constitution_skew  \n",
       "0                   0.276155  \n",
       "1                  -0.794938  \n",
       "2                   0.179824  \n",
       "3                   0.541559  \n",
       "4                   0.092206  \n",
       "\n",
       "[5 rows x 332 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_static.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "missing-machine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     501808\n",
       "unique       120\n",
       "top        era55\n",
       "freq        4893\n",
       "Name: era, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_static['era'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "familiar-grace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    137779.000000\n",
       "mean          0.500015\n",
       "std           0.223491\n",
       "min           0.000000\n",
       "25%           0.500000\n",
       "50%           0.500000\n",
       "75%           0.500000\n",
       "max           1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_static['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "appropriate-reader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1682185\n",
       "unique        332\n",
       "top          eraX\n",
       "freq         5443\n",
       "Name: era, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tournament_static['era'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "terminal-camcorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era1\n",
      "era10\n",
      "era100\n",
      "era101\n",
      "era102\n",
      "era103\n",
      "era104\n",
      "era105\n",
      "era106\n",
      "era107\n",
      "era108\n",
      "era109\n",
      "era11\n",
      "era110\n",
      "era111\n",
      "era112\n",
      "era113\n",
      "era114\n",
      "era115\n",
      "era116\n",
      "era117\n",
      "era118\n",
      "era119\n",
      "era12\n",
      "era120\n",
      "era13\n",
      "era14\n",
      "era15\n",
      "era16\n",
      "era17\n",
      "era18\n",
      "era19\n",
      "era2\n",
      "era20\n",
      "era21\n",
      "era22\n",
      "era23\n",
      "era24\n",
      "era25\n",
      "era26\n",
      "era27\n",
      "era28\n",
      "era29\n",
      "era3\n",
      "era30\n",
      "era31\n",
      "era32\n",
      "era33\n",
      "era34\n",
      "era35\n",
      "era36\n",
      "era37\n",
      "era38\n",
      "era39\n",
      "era4\n",
      "era40\n",
      "era41\n",
      "era42\n",
      "era43\n",
      "era44\n",
      "era45\n",
      "era46\n",
      "era47\n",
      "era48\n",
      "era49\n",
      "era5\n",
      "era50\n",
      "era51\n",
      "era52\n",
      "era53\n",
      "era54\n",
      "era55\n",
      "era56\n",
      "era57\n",
      "era58\n",
      "era59\n",
      "era6\n",
      "era60\n",
      "era61\n",
      "era62\n",
      "era63\n",
      "era64\n",
      "era65\n",
      "era66\n",
      "era67\n",
      "era68\n",
      "era69\n",
      "era7\n",
      "era70\n",
      "era71\n",
      "era72\n",
      "era73\n",
      "era74\n",
      "era75\n",
      "era76\n",
      "era77\n",
      "era78\n",
      "era79\n",
      "era8\n",
      "era80\n",
      "era81\n",
      "era82\n",
      "era83\n",
      "era84\n",
      "era85\n",
      "era86\n",
      "era87\n",
      "era88\n",
      "era89\n",
      "era9\n",
      "era90\n",
      "era91\n",
      "era92\n",
      "era93\n",
      "era94\n",
      "era95\n",
      "era96\n",
      "era97\n",
      "era98\n",
      "era99\n"
     ]
    }
   ],
   "source": [
    "grouped = train_static.groupby('era')\n",
    "\n",
    "for name, group in grouped:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "medium-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading new data for round: 257!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data/numerai_dataset_257.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 397M/397M [03:04<00:00, 2.17MB/s] 2021-03-27 12:43:51,296 INFO numerapi.base_api: unzipping file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data/numerai_dataset_257.zip: 397MB [03:20, 1.98MB/s]                           \n"
     ]
    }
   ],
   "source": [
    "# Download, unzip and load data\n",
    "\n",
    "download_current_data(DIR)\n",
    "train_static, val_static, tournament_static = load_data(DIR, reduce_memory=True)\n",
    "features_list = generate_features_list(train_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "judicial-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(df, name=\"submission.csv\"):\n",
    "    by = pd.read_csv('data/numerai_dataset_'+str(NAPI.get_current_round())+'/example_predictions.csv')\n",
    "    submission = pd.concat([by.drop(columns='prediction'), df['prediction']], axis=1)\n",
    "    submission = submission.set_index('id')\n",
    "    submission.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "developed-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.8/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.8/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "# Group stats\n",
    "train_with_group, val_with_group, tournament_with_group = get_group_stats(train_static), get_group_stats(val_static), get_group_stats(tournament_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "democratic-sampling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    47895.000000\n",
       "mean         0.045188\n",
       "std          0.150916\n",
       "min         -0.855008\n",
       "25%         -0.026995\n",
       "50%          0.022809\n",
       "75%          0.092002\n",
       "max          0.968062\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = train_with_group[features_list].corr()\n",
    "tricorr = corr.where(~np.tril(np.ones(corr.shape)).astype(bool))\n",
    "tricorr = tricorr.stack()\n",
    "tricorr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "severe-channel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9505659995496654"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(0.95, svd_solver='full')\n",
    "pca.fit(train_with_group[features_list])\n",
    "res = pca.transform(train_with_group[features_list])\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "unnecessary-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_group_pca = pca.transform(train_with_group[features_list])\n",
    "val_with_group_pca = pca.transform(val_with_group[features_list])\n",
    "tournament_with_group_pca = pca.transform(tournament_with_group[features_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "crazy-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_group_pca_df = pd.DataFrame(train_with_group_pca)\n",
    "val_with_group_pca_df = pd.DataFrame(val_with_group_pca)\n",
    "tournament_with_group_pca_df = pd.DataFrame(tournament_with_group_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "patent-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pd.concat([train_with_group.drop(columns=features_list).reset_index(),\n",
    "                       train_with_group_pca_df.reset_index()], axis=1)\n",
    "pca_val = pd.concat([val_with_group.drop(columns=features_list).reset_index(),\n",
    "                     val_with_group_pca_df.reset_index()], axis=1)\n",
    "pca_tournament = pd.concat([tournament_with_group.drop(columns=features_list).reset_index(),\n",
    "                            tournament_with_group_pca_df.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "imperial-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pca_train.drop(columns=['index'])\n",
    "pca_val = pca_val.drop(columns=['index'])\n",
    "pca_tournament = pca_tournament.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "veterinary-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = []\n",
    "X_tournament, y_tournament = clean_for_xgboost(pca_tournament)\n",
    "dtournament = xgboost.DMatrix(X_tournament, y_tournament)\n",
    "# model_name = 'boomkin'\n",
    "# model_id = '6bd2c44b-38bb-4918-9f08-cc1e880bc6a5'\n",
    "# model = load_model(f'models/{model_name}/model_{model_id}.pickle.dat')\n",
    "pca_tournament.loc[:,\"prediction\"] = model.predict(dtournament)\n",
    "submissions.append(pca_tournament)\n",
    "generate_submission(pca_tournament, name=f'model_{model_name}_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "demanding-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-e06180fd2d06>:5: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  correction = proportion * (exposures.dot(np.linalg.lstsq(exposures, scores)[0]))\n"
     ]
    }
   ],
   "source": [
    "def neutralize(series, by, proportion):\n",
    "    scores = series.values.reshape(-1, 1)\n",
    "    exposures = by.values.reshape(-1, 1)\n",
    "    exposures = np.hstack((exposures, np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n",
    "    correction = proportion * (exposures.dot(np.linalg.lstsq(exposures, scores)[0]))\n",
    "    corrected_scores = scores - correction\n",
    "    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n",
    "    return neutralized\n",
    "\n",
    "by = pd.read_csv('data/numerai_dataset_'+str(NAPI.get_current_round())+'/example_predictions.csv')\n",
    "neut = pd.DataFrame({'prediction': neutralize(pca_tournament['prediction'], by['prediction'], 0.3)})\n",
    "\n",
    "conc = pd.concat([by.drop(columns=\"prediction\"),neut], axis=1)\n",
    "conc.to_csv(\"neutralized_model_boomkin_submission.csv\", index=False) # submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "chief-parameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(n < 0 for n in conc.prediction.values.flatten())\n",
    "num = conc._get_numeric_data()\n",
    "num[num < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "according-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_score(preds, dtrain):\n",
    "    return \"corr\", np.corrcoef(preds, dtrain.get_label())[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tournament, y_tournament = clean_for_xgboost(pca_tournament)\n",
    "dtournament = xgboost.DMatrix(X_tournament, y_tournament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "inclusive-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train, val, model=None):\n",
    "    X_train, y_train = clean_for_xgboost(train)\n",
    "    X_val, y_val = clean_for_xgboost(val)\n",
    "\n",
    "    dtrain = xgboost.DMatrix(X_train, y_train)\n",
    "    dtest = xgboost.DMatrix(X_val, y_val)\n",
    "\n",
    "    param = {\n",
    "        'colsample_bytree': 0.7334,\n",
    "        'gamma': 1.412,\n",
    "        'max_depth': 10,\n",
    "        'min_child_weight': 18.26,\n",
    "        'subsample': 1.0,\n",
    "        'eta': 0.05,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric':'logloss',\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    evals_result = {}\n",
    "    \n",
    "    if model is not None:\n",
    "        tmodel = xgboost.train(\n",
    "            params=param,\n",
    "            dtrain=dtrain,\n",
    "#             feval=xgb_r2,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "            evals_result=evals_result,\n",
    "            xgb_model=model,\n",
    "            verbose_eval=10,\n",
    "        )\n",
    "    else:\n",
    "        tmodel = xgboost.train(\n",
    "            params=param,\n",
    "            dtrain=dtrain,\n",
    "#             feval=xgb_r2,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "            evals_result=evals_result,\n",
    "            verbose_eval=10,\n",
    "        )\n",
    "\n",
    "#     hex_gen = uuid.uuid4()\n",
    "#     print(f\"Hex number associated with this is {hex_gen}\")\n",
    "#     save_model(model, f'model_{hex_gen}.pickle.dat')\n",
    "    return tmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "veterinary-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_dataframe(df):\n",
    "    msk = np.random.rand(len(df)) < 0.8\n",
    "    train = df[msk]\n",
    "    test = df[~msk]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "italic-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current era era1\n",
      "[1]\ttrain-logloss:0.69314\ttest-logloss:0.69316\n",
      "[2]\ttrain-logloss:0.69314\ttest-logloss:0.69317\n",
      "[3]\ttrain-logloss:0.69314\ttest-logloss:0.69317\n",
      "[4]\ttrain-logloss:0.69314\ttest-logloss:0.69318\n",
      "[5]\ttrain-logloss:0.69314\ttest-logloss:0.69318\n",
      "[6]\ttrain-logloss:0.69314\ttest-logloss:0.69319\n",
      "[7]\ttrain-logloss:0.69314\ttest-logloss:0.69319\n",
      "[8]\ttrain-logloss:0.69314\ttest-logloss:0.69320\n",
      "[9]\ttrain-logloss:0.69314\ttest-logloss:0.69320\n",
      "[11]\ttrain-logloss:0.69279\ttest-logloss:0.69313\n",
      "[12]\ttrain-logloss:0.69279\ttest-logloss:0.69314\n",
      "[13]\ttrain-logloss:0.69279\ttest-logloss:0.69314\n",
      "[14]\ttrain-logloss:0.69279\ttest-logloss:0.69315\n",
      "[15]\ttrain-logloss:0.69279\ttest-logloss:0.69315\n",
      "[16]\ttrain-logloss:0.69279\ttest-logloss:0.69315\n",
      "[17]\ttrain-logloss:0.69279\ttest-logloss:0.69316\n",
      "[18]\ttrain-logloss:0.69279\ttest-logloss:0.69316\n",
      "[19]\ttrain-logloss:0.69279\ttest-logloss:0.69316\n",
      "[21]\ttrain-logloss:0.69279\ttest-logloss:0.69317\n",
      "[22]\ttrain-logloss:0.69279\ttest-logloss:0.69317\n",
      "[23]\ttrain-logloss:0.69279\ttest-logloss:0.69317\n",
      "[24]\ttrain-logloss:0.69279\ttest-logloss:0.69317\n",
      "[25]\ttrain-logloss:0.69279\ttest-logloss:0.69317\n",
      "[26]\ttrain-logloss:0.69279\ttest-logloss:0.69318\n",
      "[27]\ttrain-logloss:0.69279\ttest-logloss:0.69318\n",
      "[28]\ttrain-logloss:0.69279\ttest-logloss:0.69318\n",
      "[29]\ttrain-logloss:0.69279\ttest-logloss:0.69318\n",
      "[31]\ttrain-logloss:0.69279\ttest-logloss:0.69319\n",
      "[32]\ttrain-logloss:0.69279\ttest-logloss:0.69319\n",
      "[33]\ttrain-logloss:0.69279\ttest-logloss:0.69319\n",
      "[34]\ttrain-logloss:0.69279\ttest-logloss:0.69319\n",
      "[35]\ttrain-logloss:0.69279\ttest-logloss:0.69319\n",
      "[36]\ttrain-logloss:0.69279\ttest-logloss:0.69319\n",
      "[37]\ttrain-logloss:0.69279\ttest-logloss:0.69319\n",
      "[38]\ttrain-logloss:0.69279\ttest-logloss:0.69320\n",
      "[39]\ttrain-logloss:0.69279\ttest-logloss:0.69320\n",
      "[41]\ttrain-logloss:0.69215\ttest-logloss:0.69309\n",
      "[42]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[43]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[44]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[45]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[46]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[47]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[48]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[49]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[51]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[52]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[53]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[54]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[55]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[56]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[57]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[58]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[59]\ttrain-logloss:0.69215\ttest-logloss:0.69310\n",
      "[61]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[62]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[63]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[64]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[65]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[66]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[67]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[68]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[69]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[71]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[72]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[73]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[74]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[75]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[76]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[77]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[78]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[79]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[81]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[82]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[83]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[84]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[85]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[86]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[87]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[88]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[89]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[91]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[92]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[93]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[94]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[95]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[96]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[97]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[98]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[99]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[101]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[102]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[103]\ttrain-logloss:0.69215\ttest-logloss:0.69311\n",
      "[104]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[105]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[106]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[107]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[108]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[109]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[111]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[112]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[113]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[114]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[115]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[116]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[117]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[118]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[119]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[121]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[122]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[123]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[124]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[125]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[126]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[127]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[128]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[129]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n",
      "[131]\ttrain-logloss:0.69158\ttest-logloss:0.69305\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-fdcf042c068a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current era\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-45f3fe729d9d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train, val, model)\u001b[0m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         tmodel = xgboost.train(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mdtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    220\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1268\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grouped = pca_train.groupby('era')\n",
    "for name, group in grouped:\n",
    "    train, test = train_test_dataframe(group)\n",
    "    print(\"Current era\", name)\n",
    "    model = None\n",
    "    model = train_model(train, test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "surprised-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, f'model_boomkin_testing_logloss_1000.pickle.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cloudy-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyp_xgb(max_depth, subsample, colsample_bytree, min_child_weight, gamma):\n",
    "    params = {\n",
    "      'eta': 0.05,\n",
    "      'objective': 'reg:squarederror',\n",
    "      'eval_metric':'logloss', # Optional --> Use eval_metric if you want to stop evaluation based on eval_metric \n",
    "      'verbosity': 0\n",
    "    }\n",
    "    params['max_depth'] = int(round(max_depth))\n",
    "    params['subsample'] = max(min(subsample, 1), 0)\n",
    "    params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n",
    "    params['min_child_weight'] = int(min_child_weight)\n",
    "    params['gamma'] = max(gamma, 0)\n",
    "    \n",
    "    scores = xgboost.cv(params,\n",
    "                    dtrain,\n",
    "                    num_boost_round=10,\n",
    "                    verbose_eval=False,\n",
    "                    early_stopping_rounds=5,\n",
    "                    feval=correlation_score,\n",
    "                    maximize=True,\n",
    "                    nfold=5)\n",
    "    return  scores['test-corr-mean'].iloc[-1]\n",
    "pds ={\n",
    "  'min_child_weight':(14, 20),\n",
    "  'gamma':(0, 5),\n",
    "  'subsample':(0.5, 1),\n",
    "  'colsample_bytree':(0.1, 1),\n",
    "  'max_depth': (5, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = clean_for_xgboost(pca_train)\n",
    "dtrain = xgboost.DMatrix(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "christian-culture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.02035 \u001b[0m | \u001b[0m 0.5648  \u001b[0m | \u001b[0m 2.853   \u001b[0m | \u001b[0m 5.142   \u001b[0m | \u001b[0m 15.03   \u001b[0m | \u001b[0m 0.8426  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.02446 \u001b[0m | \u001b[95m 0.8505  \u001b[0m | \u001b[95m 1.535   \u001b[0m | \u001b[95m 9.468   \u001b[0m | \u001b[95m 18.33   \u001b[0m | \u001b[95m 0.595   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.02291 \u001b[0m | \u001b[0m 0.5988  \u001b[0m | \u001b[0m 1.761   \u001b[0m | \u001b[0m 5.909   \u001b[0m | \u001b[0m 18.71   \u001b[0m | \u001b[0m 0.9827  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.01973 \u001b[0m | \u001b[0m 0.3091  \u001b[0m | \u001b[0m 0.4178  \u001b[0m | \u001b[0m 8.018   \u001b[0m | \u001b[0m 18.37   \u001b[0m | \u001b[0m 0.6381  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.01749 \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 2.589   \u001b[0m | \u001b[0m 5.242   \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 0.5935  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.02388 \u001b[0m | \u001b[0m 0.7079  \u001b[0m | \u001b[0m 1.778   \u001b[0m | \u001b[0m 5.855   \u001b[0m | \u001b[0m 18.67   \u001b[0m | \u001b[0m 0.7764  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.02366 \u001b[0m | \u001b[0m 0.9361  \u001b[0m | \u001b[0m 1.604   \u001b[0m | \u001b[0m 9.371   \u001b[0m | \u001b[0m 18.53   \u001b[0m | \u001b[0m 0.6457  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.02189 \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 1.917   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 18.0    \u001b[0m | \u001b[0m 0.5314  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.0202  \u001b[0m | \u001b[0m 0.5885  \u001b[0m | \u001b[0m 2.221   \u001b[0m | \u001b[0m 7.087   \u001b[0m | \u001b[0m 16.12   \u001b[0m | \u001b[0m 0.5198  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.02263 \u001b[0m | \u001b[0m 0.9528  \u001b[0m | \u001b[0m 0.9688  \u001b[0m | \u001b[0m 9.567   \u001b[0m | \u001b[0m 18.29   \u001b[0m | \u001b[0m 0.5154  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.01902 \u001b[0m | \u001b[0m 0.8245  \u001b[0m | \u001b[0m 3.435   \u001b[0m | \u001b[0m 7.455   \u001b[0m | \u001b[0m 19.02   \u001b[0m | \u001b[0m 0.8532  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.0223  \u001b[0m | \u001b[0m 0.5257  \u001b[0m | \u001b[0m 1.59    \u001b[0m | \u001b[0m 9.097   \u001b[0m | \u001b[0m 18.05   \u001b[0m | \u001b[0m 0.5567  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.02312 \u001b[0m | \u001b[0m 0.222   \u001b[0m | \u001b[0m 0.1067  \u001b[0m | \u001b[0m 6.011   \u001b[0m | \u001b[0m 17.25   \u001b[0m | \u001b[0m 0.9774  \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 0.02553 \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 1.431   \u001b[0m | \u001b[95m 9.719   \u001b[0m | \u001b[95m 18.5    \u001b[0m | \u001b[95m 0.865   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.01938 \u001b[0m | \u001b[0m 0.6925  \u001b[0m | \u001b[0m 3.281   \u001b[0m | \u001b[0m 9.326   \u001b[0m | \u001b[0m 19.56   \u001b[0m | \u001b[0m 0.8476  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.02064 \u001b[0m | \u001b[0m 0.2922  \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 9.816   \u001b[0m | \u001b[0m 18.78   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.02288 \u001b[0m | \u001b[0m 0.6952  \u001b[0m | \u001b[0m 0.6568  \u001b[0m | \u001b[0m 7.45    \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 0.5894  \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.02606 \u001b[0m | \u001b[95m 0.7334  \u001b[0m | \u001b[95m 1.412   \u001b[0m | \u001b[95m 9.64    \u001b[0m | \u001b[95m 18.26   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.02602 \u001b[0m | \u001b[0m 0.3487  \u001b[0m | \u001b[0m 1.248   \u001b[0m | \u001b[0m 9.791   \u001b[0m | \u001b[0m 18.08   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.0223  \u001b[0m | \u001b[0m 0.2663  \u001b[0m | \u001b[0m 1.146   \u001b[0m | \u001b[0m 9.958   \u001b[0m | \u001b[0m 17.44   \u001b[0m | \u001b[0m 0.9252  \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Surrogate model\n",
    "optimizer = BayesianOptimization(hyp_xgb, pds, random_state=101)                   \n",
    "# Optimize\n",
    "optimizer.maximize(init_points=5, n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "|  18       |  0.02606  |  0.7334   |  1.412    |  9.64     |  18.26    |  1.0      |\n",
    "|  14       |  0.02553  |  0.5      |  1.431    |  9.719    |  18.5     |  0.865    |\n",
    "|  2        |  0.02446  |  0.8505   |  1.535    |  9.468    |  18.33    |  0.595    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
